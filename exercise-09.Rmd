---
title: "exercise-09"
author: "SLCornett"
date: "3/29/2022"
output: 
  html_document: 
    theme: yeti
    highlight: pygments
editor_options: 
  chunk_output_type: console
---
**Practice_Simple_Linear_Regression**
```{r}
#library(mosaic)
library(tidyverse)
library(manipulate) 
library(broom)
library(patchwork)
library(skimr)
library(infer)
library(dplyr)
library(ggplot2)
library(lmodel2)
```


1. Using the {tidyverse} read_csv() function, load the “Street_et_al_2017.csv” dataset from this URL as a “tibble” named d.
```{r}
f <- "https://raw.githubusercontent.com/difiore/ada-2022-datasets/main/Street_et_al_2017.csv"
d <- read_csv(f, col_names = TRUE)
```


2. Do a quick exploratory data analysis where you generate the five-number summary (median, minimum and maximum and 1st and 3rd quartile values), plus mean and standard deviation, for each quantitative variable
```{r}
skim(d)
```


[note to self: $\beta$ = beta letter]


3. Plot brain size (**ECV**) as a function of social group size (**Group_size**), longevity (**Longevity**), juvenile period length (**Weaning**), and reproductive lifespan(**Repro_lifespan**)
```{r}
# alternative method: plot(x = , y = )

# ECV by group size
gs <- ggplot(data = d, aes(x = ECV, y = Group_size)) 
gs <- gs + geom_point(na.rm=TRUE) # make it a scatterplot

#ECV by longevity
lg <- ggplot(data = d, aes(x = ECV, y = Longevity))
lg <- lg + geom_point(na.rm=TRUE)

#ECV by Weaning
wean <- ggplot(data = d, aes(x = ECV, y = Weaning))
wean <- wean + geom_point(na.rm = TRUE)

#ECV by Reproductive lifespan
rl <- ggplot(data = d, aes(x = ECV, y = Repro_lifespan))
rl <- rl + geom_point(na.rm = TRUE)

gs+lg+wean+rl
```



4. Derive by hand the ordinary least squares regression coefficients ($\beta1$) and ($\beta0$) for ECV as a function of social group size. 
[HINT: You will need to remove rows from your dataset where one of these variables is missing.]
```{r}
#filtered d in the block above
df <- d %>% # pinned and exclamation mark before is "not"
  filter(!is.na(ECV) & !is.na(Group_size)) # filters out all the rows that have NA in them and assigns to a new data set, df (aka d_mod)
# β1 by hand
b1 <- cor(df$ECV, df$Group_size) * sd(df$ECV)/sd(df$Group_size)
b1 # this checks out

# beta0 by hand
b0 <- mean(df$ECV) - b1*mean(df$Group_size)
b0 # this checks out

#t-test code from class
#t_b1 <- b1/SE_b1
#t_b0 <- b0/SE_b0
```


5. confirm that you get the same results using the 'lm()' fxn.
```{r}
model <- lm(formula = ECV ~ Group_size, data = d)
model

#summary of model
summary(model) #matches lm function output
#linear model fxn smart so don't need to filter out the NAs when running this, ie can use d instead of df
model_sum <- tidy(model)
model_sum

#residuals = how far each observation deviates from the predicted line
residuals <-  df$ECV - (b0 + b1 * df$Group_size) # or residuals <- model$residuals

#num <- sum(residuals^2)/(length(residuals)-2) #only squaring Group size, not the whole things
num <- sum(residuals^2)
den <- sum((df$Group_size - mean(df$Group_size))^2) * (nrow(df) - 2)  #need to define n as the number of rows, either as a variable or as nrow(df)
```


6. Repeat the above analysis for different groups of primates (catarrhines, platyrrhines, strepsirhines (big radiation, including lemurs)) separately.These are stored in the variable *Taxonomic_group*.
```{r}
# Selecting by taxonomic group. i am vey proud of this. 
#Catarrhines
# filtering for just these dudes
catarrhines <- df %>% filter(Taxonomic_group == "Catarrhini") 
# b1 by hand
cata_b1 <- cor(catarrhines$ECV, catarrhines$Group_size) * (sd(catarrhines$ECV)/sd(catarrhines$Group_size))
cata_b1
# b0 by hand
cata_b0 <- mean(catarrhines$ECV) - cata_b1 * mean(catarrhines$Group_size)
cata_b0

#cata lm 
cata_m <- lm(formula = ECV ~ Group_size, data = catarrhines)
summary(cata_m)

#platyrrhines
#filtering for these dudes
platyrrhines <- df %>% filter(Taxonomic_group == "Platyrrhini")
# b1 by hand
platy_b1 <- cor(platyrrhines$ECV, platyrrhines$Group_size) * (sd(platyrrhines$ECV)/sd(platyrrhines$Group_size))
platy_b1
# b0 by hand
platy_b0 <- mean(platyrrhines$ECV) - platy_b1 * mean(platyrrhines$Group_size)
platy_b0

#platy lm
platy_m <- lm(formula = ECV ~ Group_size, data = platyrrhines)
summary(platy_m)

#strepsirhines
# filtering for these dudes
strepsirhines <- df %>% filter (Taxonomic_group == "Strepsirhini") 
# b1 by hand
strep_b1 <- cor(strepsirhines$ECV, strepsirhines$Group_size) * (sd(strepsirhines$ECV)/sd(strepsirhines$Group_size))
strep_b1
# b0 by hand
strep_b0 <- mean(strepsirhines$ECV) - strep_b1 * mean(strepsirhines$Group_size)
strep_b0

#lm for strep
strep_m <- lm(formula = ECV ~ Group_size, data = strepsirhines)
summary(strep_m)
```
7. Do your regression coefficients differ among the taxonomic groups? How might you determine this? 
The regression coefficients differ slightly among the 3 groups; I determined this by comparing each groups linear model summaries. This can also be determined just by comparing the regression coefficients. 



8. For your first regression of *ECV on social group size* (above), calculate the *standard error for the slope coefficient*, the *95% CI*, and the *p value* associated with this coefficient by hand. Also extract this same information from the results of running the lm() function.
```{r}
#standard error of the slope coefficient
SE_b1 <- sqrt(num/den) # fixed, now working!
SE_b1

# SE_b0 <- SE_b1 * sqrt(sum(df$Group_size^2)/length(df$Group_size)) # do not need
# SE_b0

#95% CI of model (initial summary stats)
alpha <- 0.05
lower <- model_sum$estimate - qt(1 - alpha / 2, df = nrow(df) - 2) * model_sum$std.error #df dataframe without the NAs
upper <- model_sum$estimate + qt(1 - alpha / 2, df = nrow(df) - 2) * model_sum$std.error

CI <- cbind(lower, upper) # making CI output a table
rownames(CI) <- c("(Intercept)", "Group_size")
colnames(CI) <- c(paste0(as.character(alpha/2 * 100), " %"),paste0(as.character((1-alpha/2) * 100), " %"))
CI

#calculate the p-value
model_sum$calc.statistic <- (model_sum$estimate-0)/model_sum$std.error 
model_sum$calc.p.value <- 2 * pt(model_sum$calc.statistic, df = nrow(df)-2, lower.tail = FALSE)
model_sum

# extract using lm 
model_sum # possibly wrong?
```


9. Then, use a permutation approach with 1000 permutations to generate a null sampling distribution for the slope coefficient. What is it that you need to permute? What is the p value associated with your original slope coefficient? You can use either the percentile method (i.e., using quantiles from actual permutation-based null sampling distribution) or a theory-based method (i.e., using the standard deviation of the permutation-based null sampling distribution as the estimate of the standard error), or both, to calculate this p value.
```{r}
# first define alpha, CI boundaries, and critical values
alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha / 2
p_upper <- 1 - (alpha / 2)
degrees_of_freedom <- nrow(df) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

# original slope = og slope
og_slope <- lm(data = df, ECV ~ Group_size) %>% 
  tidy(conf.int = TRUE, conf.level = confidence_level) %>%# tidy the model to make it a table
  mutate( # add the CI based on the t distribution to the new table
    lower = estimate - std.error * critical_value,
    upper = estimate + std.error * critical_value
  ) %>%
  filter(term == "Group_size")
og_slope # show model results for slope of weight

# og slope p value (adds it to the tibble above)
og_slope$calc.statistic <- (og_slope$estimate-0)/og_slope$std.error 
og_slope$calc.p.value <- 2 * pt(og_slope$calc.statistic, df = nrow(df)-2, lower.tail = FALSE)
og_slope # returns calculated p-value

# permuted slope (perm_slope) - to compare to og_slope
perm_slope <- df %>% 
  specify(ECV ~ Group_size) %>% # specify model (same as above for info included)
  hypothesize(null = "independence") %>% # use a null hypothesis of independence
  generate(reps = 1000, type = "permute") %>% # generate permutation replicates, 1000 permutations
  calculate(stat = "slope")# calculate the slope statistic
print(perm_slope)

# p-value for perm_slope vs. og_slope
p_value <- perm_slope %>% 
  mutate(abs_stat = abs(stat)) %>% # add a column of the absolute value of the slope
  summarize( # calculate a summary statistic
    # calculate proportion of cases where the absolute value
    # of the permuted slope is greater than or equal to the 
    # absolute value of the observed slope
    estimate = mean(abs_stat >= abs(pull(og_slope, estimate)))
  )
p_value

# create confidence intervals for perm_slope
perm_slope_sum <- perm_slope %>% # summarize the mean, t distribution based CI, and quantile-based CI
  summarize(
    estimate = mean(stat),  # mean of stat = mean of slope
    se = sd(stat),  # standard error of stat
    lower = estimate - se * critical_value, # calculate the CI based on the SE and t distribution
    upper = estimate + se * critical_value
    #perm_lower = quantile(stat, p_lower),  # calculate the CI based on the quantile (percentile) method
    #perm_upper = quantile(stat, p_upper)
  )

# show summary of permuted sampling distribution
perm_slope_sum
summary(perm_slope_sum)
```


10. Use bootstrapping to generate a 95% CI for your estimate of the slope coefficient using both the percentile method and the theory-based method (i.e., based on the standard deviation of the bootstrapped sampling distribution). What is the p value associated with your observed slope coefficient based on each of these methods?  
```{r}
boot_slope <- df %>%
  specify(ECV ~ Group_size) %>% # specify model, same as permuted
  generate(reps = 1000, type = "bootstrap") %>% # generate bootstrap replicates, 1000, like permutations
  calculate(stat = "slope") # calculate the slope statistic
print(boot_slope) # slopes from first few bootstrap replicates

# create confidence intervals for regression coefficients: theory based methods
boot_CI_1 <- boot_slope %>% # summarize the mean
  summarize( #t distribution based CI
    estimate = mean(stat), # mean of stat
    se = sd(stat),    # standard error of stat
    lower = estimate - se * critical_value, # calculate the CI based on the SE and t distribution
    upper = estimate + se * critical_value, 
  )
summary(boot_CI_1) # show summary of bootstrap sampling distribution

# create confidence intervals for regression coefficients: percentile method
boot_CI_2 <- boot_slope %>% # summarize the mean
  summarize( #quantile-based CI
    estimate = mean(stat), # mean of stat
    se = sd(stat),    # standard error of stat
    boot_lower = quantile(stat, p_lower), # calculate the CI based on the quantile (percentile)  method
    boot_upper = quantile(stat, p_upper) 
  )
summary(boot_CI_2) # show summary of bootstrap sampling distribution

```
11. Do these CIs suggest that your slope coefficient is different from zero? Yes. but they look different from the % CIs from the model summary. 
